{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A spam classifier using multiple HuggingFace spam datasets to train a single classifer, and testing it on a single dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the path to the directory containing this notebook\n",
    "notebook_dir = os.path.abspath('')\n",
    "# Get the path to the parent directory of the notebook directory\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "# Add the parent directory to the Python module search path\n",
    "sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dataset import Dataset, MergedDataset\n",
    "from model import ClassificationModel\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "type = \"spam_multi\"\n",
    "\n",
    "with open (f'configs/{type}.json') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset sms_spam (/Users/dmvaldman/.cache/huggingface/datasets/sms_spam/plain_text/1.0.0/53f051d3b5f62d99d61792c91acefe4f1577ad3e4c216fb0ad39e30b9f20019c)\n",
      "Loading cached processed dataset at /Users/dmvaldman/.cache/huggingface/datasets/sms_spam/plain_text/1.0.0/53f051d3b5f62d99d61792c91acefe4f1577ad3e4c216fb0ad39e30b9f20019c/cache-47ab3183d2d5e948.arrow\n",
      "Found cached dataset csv (/Users/dmvaldman/.cache/huggingface/datasets/Ngadou___csv/Ngadou--Spam_SMS-56dcaf8be36206bc/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "Loading cached processed dataset at /Users/dmvaldman/.cache/huggingface/datasets/Ngadou___csv/Ngadou--Spam_SMS-56dcaf8be36206bc/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-ad170945d5aaadf6.arrow\n",
      "Found cached dataset csv (/Users/dmvaldman/.cache/huggingface/datasets/adamlouly___csv/adamlouly--enron_spam_data-de5c1c25b37e4492/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "Loading cached processed dataset at /Users/dmvaldman/.cache/huggingface/datasets/adamlouly___csv/adamlouly--enron_spam_data-de5c1c25b37e4492/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-0e31c028bdda29dc.arrow\n",
      "Found cached dataset csv (/Users/dmvaldman/.cache/huggingface/datasets/adamlouly___csv/adamlouly--enron_spam_data-de5c1c25b37e4492/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|██████████| 40/40 [00:20<00:00,  1.92it/s]        \n"
     ]
    }
   ],
   "source": [
    "single_dataset_config = config[\"datasets\"][2]\n",
    "dataset_train = MergedDataset(type, config, save=True, split='train')\n",
    "dataset_test = Dataset(type, single_dataset_config, save=True, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results {'accuracy': 0.9815706333684369, 'f1': 0.9784728934188559}\n",
      "Validation Results: {'accuracy': 0.9815, 'f1': 0.9813789632611978}\n"
     ]
    }
   ],
   "source": [
    "config_model = config['model']\n",
    "model = ClassificationModel(config_model)\n",
    "\n",
    "result_train = model.fit(dataset_train)\n",
    "print('Training Results', result_train)\n",
    "\n",
    "result_test = model.test(dataset_test)\n",
    "print('Validation Results:', result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'models/{type}/model.npz'\n",
    "model.save(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
